# Hello DES INV 202 Student!
Welcome to your new GitHub repository! 

# Outline
[week 1](README.md#week-1-example-report-1)

week 2, etc...

---

# Github Background Information & Context
If you‚Äôre new to GitHub, you can think of this as a shared file space (like a Google Drive folder, or a like a USB drive that‚Äôs hosted online.) 

This is your space to store project files, videos, PDFs, notes, images, etc., and (hopefully, neatly) organize so it's easy for viewers (and you!) to navigate. That said, it‚Äôs super easy for you to share any file or folder with us (your TDF instructional team) - just send us the link!  As a start, feel free to simply add images to the `/assets` folder, which is located [here](/assets). 

The specific file that I‚Äôm typing into right now is the **README.md** for this repo. 
##### (üí° TIP: The .md indicates that we‚Äôre using [Markdown formatting.](https://www.markdownguide.org/cheat-sheet/)) #####
<h6> (üí° TIP 2: GitHub Markdown supports <a href="https://gist.github.com/seanh/13a93686bf4c2cb16e658b3cf96807f2"> <em>HTML formatting</em> too, including emojis üòÑ</a>, in case that helps!) </h6>

### :star: Whatever you write in your **README.md** will show up on the ‚Äúfront page‚Äù of your GitHub repo. This is where we‚Äôll be looking for your [weekly progress reports](https://github.com/Berkeley-MDes/24f-desinv-202/wiki/3.0-Weekly-Submissions#weekly-progress-report). They might look something like this: ###


---


# Week of 09/05/2024

This week, I learned how to use a laser cutting printer and printed a tea coaster for trial.

### Reflection

It takes multiple attempts to see the proper red outlines to cut through.

- First Attempt: I put the line stroke as 0.01, and it didn't show up. The other student told me to change it to 0.001, but it still didn't appear.
- Second Attempt: To figure out what the problem is, I just drew a simple square colored 255,0,0 and stroked 0.001px. Then the outline appeared. The problem is the pattern I made.
Third Attempt: I thought the problem was that the pattern layer and the outline overlapped, so I decreased the size of the pattern so that it did not overlap, and it still didn't work
- Third Attempt: I rasterized and expanded the pattern layer before, but I didn't expand it as a vector after masking it. So I made it sure to be fully vectorized. Then it finally worked.

### Speculations

It was so fun to try new equipment that I had never used before. This time, I focused on learning how to use it, which took more time than I expected. I would love to test other cutting settings like etching and more complex features.

### Images & Video
![IMG_6273](https://github.com/user-attachments/assets/358bf897-2883-4a4f-a6fd-049908b7d7cf)
![IMG_6280](https://github.com/user-attachments/assets/e4662d84-3d25-4794-8ad5-92c845167b1d)



### Drawing
<img width="588" alt="Screenshot 2024-09-05 at 1 56 02‚ÄØPM" src="https://github.com/user-attachments/assets/3f4bd015-692b-4d6c-831e-7734a5a8b35d">
<img width="395" alt="Screenshot 2024-09-05 at 12 57 03‚ÄØPM" src="https://github.com/user-attachments/assets/26d23bf2-ddc0-4368-8c40-59adcf624d02">


----

# Week of 09/12/2024
This week, I explored Rhino and Grasshopper and developed some ideas for my computational design project.

## Reflection
I could understand the role of Grasshopper and how the algorithm works.
However, I still don't fully grasp the types of algorithms and how they affect the models.
Currently, I‚Äôm teaching myslef Blender, and I made a donut model to try printing in 3d. I'm going to try printing it in 3D next week.

Also, I started thinking of the object for project 1. Since I tried laser cutting last week, I am excited to try it again. Based on last week's reflection, I will make a helpful, structural object.

## Speculations
(about grasshopper)
I felt lost while exploring the features, and it's because I didn't have a certain goal (project) that I aimed to create. Next time, I will set a goal and plan to make it, then it could be much more feasible to learn this program.

(about laser cutting)
I made some diagrams aligned with the user's context and pain points, including plans to make the object.
I decided to make a headphone stand reflecting my daily life as a user.

<img width="1318" alt="Screenshot 2024-09-19 at 10 28 39‚ÄØAM" src="https://github.com/user-attachments/assets/7be18a29-d905-4589-abd5-2525b4271c2c">



## Images & Video
<img width="552" alt="Screenshot 2024-09-12 at 3 06 16‚ÄØPM" src="https://github.com/user-attachments/assets/a7a127dc-c130-45b0-8603-f7db16459e70">
<img width="1420" alt="Screenshot 2024-09-12 at 3 02 17‚ÄØPM" src="https://github.com/user-attachments/assets/7abda7d5-c397-4a71-b1b3-8a95a33e72e0">


## Sketch
![IMG_6671](https://github.com/user-attachments/assets/6807338c-b783-48cb-8157-4a48548f40f5)



----

# Week of 09/19/2024
I made a final prototype of my headphone stand and tried out 3d printing.
Also, I completed a deliverable video for my cohorts showcasing my journey with this project.

## Reflection

This week, I put in a lot of work to meet my project submission deadline. 
First, I transferred the headphone stand sketch from last week into Adobe Illustrator and laser-cut it. Installing it at home, I was pleased with the result. However, realizing that it also couldn't keep my sunglasses in place, I added a sunglasses hanger and remade the stand.

I recorded a lot of video footage of this process to share in class and edited it using Adobe Premiere Pro.

## Speculations

This week‚Äôs project work, from designing a headphone stand to adapting it into a multifunctional piece, 
focused on the essence of practical design. 

Initially, the stand was meant only for headphones, but adding a sunglasses hanger revealed how each iteration responds to new needs. 
Sharing the process through video deepened my understanding, turning a simple project into a dynamic exploration of form and function. 
It makes me wonder‚Äîcould this be the start of more versatile designs that adapt to everyday life in unexpected ways?

## Images & Video


https://github.com/user-attachments/assets/4d9697f5-d648-49bc-8821-83c5a9e566b2



![IMG_6637](https://github.com/user-attachments/assets/76333a33-2e05-4be2-b6b5-0b4ac0de78a7)

![IMG_6645](https://github.com/user-attachments/assets/6616b3f1-1d54-438e-9916-fe658a260ab1)


https://github.com/user-attachments/assets/7a416543-56bb-4722-b74d-542a14965a35
<img width="1408" alt="Screenshot 2024-09-19 at 1 12 18‚ÄØPM" src="https://github.com/user-attachments/assets/067f4a06-989b-4f60-aced-109811b1f5f8">


## Sketch
<img width="507" alt="Screenshot 2024-09-19 at 1 14 27‚ÄØPM" src="https://github.com/user-attachments/assets/619dd681-263f-49bc-8e4b-d9a228b8c3f0">
<img width="540" alt="Screenshot 2024-09-19 at 1 14 39‚ÄØPM" src="https://github.com/user-attachments/assets/c9c1defb-bbd1-4a7b-be19-10f271ba0d39">


------

# Week of 09/26/2024

## Mapping Interaction Ecosystems

### Entertainment & Media Ecosystems

**First,** I checked my screen time to see which apps I use frequently and to understand their categories.

![IMG_6741](https://github.com/user-attachments/assets/36c8c0f3-a36f-4520-bb97-35855c08e0fc)

**Next**, I considered the purpose of my app usage and how I use them, dividing these two factors into the x and y axes to create a positioning map.
- X: Informational <-> Entertainment
- Y: Social (connecting with other people) <-> Content Consuming (not connecting other people, just consuming other's content)

<img width="1316" alt="Screenshot 2024-09-26 at 1 12 24‚ÄØPM" src="https://github.com/user-attachments/assets/bc193914-ee5a-45df-bcad-8e8331ab993e">


**Last**, I reclassified the purposes of my app usage once more. I identified that the flow of obtaining, consuming information, and interacting with others is connected linearly, and I organized how this flow operates.

1. I obtain official information about school and job-related matters through Slack, WhatsApp cohort group chats, and LinkedIn. I mainly get information about official events from the school or companies, internship opportunities, exhibitions, and competitions.

2. If the information from step 1 is insufficient or if I need others' opinions or additional comments on that information, I turn to Reddit for further insights. At this stage, extra information is added to the formal information obtained earlier, creating a flow where the overall amount of information increases.

3. I gather a mix of official and unofficial information through platforms like X (formerly Twitter), TikTok, and YouTube. This information is often entertainment-oriented, helping me relieve stress or stay updated on social trends.

4. I process the information obtained from steps 1, 2, and 3 and engage in conversations with others, using this as a means of social networking. Others also go through similar steps, and there‚Äôs a flow where we exchange the information we've gathered from these processes.


<img width="1017" alt="Screenshot 2024-09-26 at 1 14 32‚ÄØPM" src="https://github.com/user-attachments/assets/12d5183c-29f4-4ffe-acbc-75ace387f151">

-----

# Week of 2024/10/03

This week, I installed the platform called Particle and learned the basics of C++ using the Photon. Since it was my first time using VSCode, it took me a while to get familiar with the interface, but I‚Äôm proud to have successfully completed the basic setup and monitoring.

However, my progress has been slower than Jeff's expectations, so I plan to work harder next week to catch up.

### Process

1. 9/26 in class: I wrote code where the entire "hello world!" sentence appears at 3-second intervals.
2. 9/30 homework: I wrote code where each character of "hello world!" appears at 3-second intervals.
 ```
   void loop() {
  if (count == size_hello) {
    count = 0;
  }

  // Test with simpler log output to ensure logging works correctly
  Log.info("current character: %c", hello[count]);
  
  count++;
  delay(300);
}
```

https://github.com/user-attachments/assets/1dbbd4d1-1987-471a-a48b-7492cd9b260f


3. Next, I adjusted settings like the class name and delay, and instead of the phrase "hello world!", I made each character of my name appear one by one.

 ```
#include "Particle.h"

// Define the system setup and log handler
SYSTEM_MODE(AUTOMATIC);
SYSTEM_THREAD(ENABLED);
SerialLogHandler logHandler(LOG_LEVEL_ALL);  // Î°úÍ∑∏ Î†àÎ≤®ÏùÑ ALLÎ°ú ÏÑ§Ï†ï

char myname[] = "Jeongmin Lee ";
int size_myname = sizeof(myname) - 1;
int count = 0;

void setup() {
  Log.info("-------------Welcome to the myname World example!-------------");
}

void loop() {
  if (count == size_myname) {
    count = 0;
  }

  // Test with simpler log output to ensure logging works correctly
  Log.info("current character: %c", myname[count]);
  
  count++;
  delay(300);
}

 ```

https://github.com/user-attachments/assets/375dc102-5986-487c-80de-9db439cb7d93


### Failure
For some unknown reason, I opened the example file that Jeff provided and started monitoring, but despite setting everything up correctly, the monitoring kept failing. When I copied and pasted the code into the file I was originally working on and started monitoring, it worked fine, but I couldn't figure out why.



### Reflection

Though the progress is very slow, I‚Äôm grateful to be learning bit by bit. By next week, I will ensure that I can monitor the display on Photon. Additionally, I‚Äôll challenge myself to try out the example Jeff explained, where the LED blinks using a button.


### Speculation

What could I create with what I learned today?

I could make something that outputs words of encouragement or support at specific times. For example, when feeling tired from working for long periods, it could show uplifting words every two hours. Or, during a discussion, when I feel hesitant to speak up, it could display a message to encourage me to share my thoughts.

Small words can easily influence people's moods and attitudes. The text display I learned to create this week could serve this purpose.


-----
# Week of 2024/10/10


This experiment explores sensor-based projects using the Stemma QT interface with a Particle device. It involves soldering the interface, configuring the project in Visual Studio Code, and experimenting with the demo firmware. The objective is to map sensor values to outputs like LED control and share data between devices using Particle.publish() and Particle.subscribe(). This report summarizes the findings and considerations.


### Soldering
![IMG_6949](https://github.com/user-attachments/assets/f1afd0aa-b629-4541-abe8-dbf5eb11d0d3)
![IMG_6950](https://github.com/user-attachments/assets/d8065872-fe6f-4f03-bc8d-187215a20c26)

Josh helped me with how to do soldering and instructed me to use it safely.

### Reflection
The experiment showed the potential of integrating sensor data with various outputs and sharing sensor values across devices. While the basic demo firmware provided limited functionality, through the use of map(), constrain(), and data smoothing techniques, sensor values could be mapped to other processes such as LED brightness control. The feasibility of sharing sensor data via Particle‚Äôs cloud was explored, highlighting both opportunities and challenges in latency and data accuracy. Further work could involve expanding the output options and testing real-time data synchronization across multiple devices.

### Speculation
Based on this experiment, Subin, Hannah, and I grouped as a team for the 2nd project.
Our concept is about a calming down system for people who are arguing/conflicting.
We are going to use sound input and recognize the sound, whether it is fighting or not.
Then, the music sound will be used as an output.
Using a pulse sensor would indicate calmness.



### Diagram: Design and Data Flow
The following diagram represents the system design and data flow:

 ```
[ Stemma QT Sensors ] --> [ Particle Device ]
        |                    |
        V                    V
[ Sensor Data Mapping ]    [ Publish Sensor Data to Cloud ]
        |                    |
        V                    V
[ LED Control ]         [ Subscribe to Data on Second Device ]
                             |
                             V
                 [ Second Device Uses Data for Output ]

 ```

-----

# Week of 2024/10/17

This week, our team developed each own part. My part is making a physical artifact for containing a speaker, mic and photon.

## Process

### for frame
1. I designed a simple box-shaped product with 2 feet (10x10x4cm) to put all things in it.
2. Also, I made a little hole to put the wires out.

### for lids
Then, I designed the front and back lids. 
1. The back is just a simple panel,
2. but the front lid should have a hole for the mic, which is a 1cm hole.
3. Also, I made lined holes that make sound come out.

### Frame + lids
I made 4.5mm holes on each edge of the frame and added 4 extrudes on the front and back lids to make them fit each other.


## Sketch
![IMG_7261](https://github.com/user-attachments/assets/a9b734bf-1d90-4f0e-a910-110f29e759a3)


## Image
![IMG_7263](https://github.com/user-attachments/assets/447f19f8-5c5c-4f8d-80b4-c4c69325d527)



https://github.com/user-attachments/assets/d1685436-6a55-4642-8f3b-1ec49e268724




## Reflection
I initially sketched the ultrasonic device to look like a face with eyes, nose, and mouth, thinking it was a speaker. However, I realized it wasn't a speaker and, with Jeff's help, I was able to get a larger speaker. Although it's a bit big, it fortunately fits. Over the weekend, I plan to shoot the demo video and edit the final version.

- [TDF Wiki](https://github.com/Berkeley-MDes/24f-desinv-202/wiki) - the ultimate source for truth and information about the course and assignments
- [Google Drive Folder](https://drive.google.com/drive/u/0/folders/1DJ1b6sSDwHXX6NRcQYt10ivyQSgU0ND6) - slides and other resources
- [bCourses](https://bcourses.berkeley.edu/courses/1537533) - where the grading happens
